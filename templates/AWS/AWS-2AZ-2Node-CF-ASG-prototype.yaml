AWSTemplateFormatVersion: 2010-09-09
Description: Gala Node Stack
Parameters:
  APIKey:
    Type: String
    Description: API Key to be stored as Secure Parameter
  Workloads:
    Type: String
    Description: Workloads to run on Node space separated. Ex. founders player
    Default: founders player
  LatestAmazonLinuxAMIId:
    Type: "AWS::SSM::Parameter::Value<AWS::EC2::Image::Id>"
    Default: "/aws/service/ami-amazon-linux-latest/amzn2-ami-hvm-x86_64-gp2"
    Description: Ami to use, DO NOT CHANGE
Resources:
  VPC:
    Type: 'AWS::EC2::VPC'
    Properties:
      CidrBlock: 10.0.0.0/16
      EnableDnsSupport: true
      EnableDnsHostnames: true
      InstanceTenancy: default
      Tags:
        - Key: Stack Name
          Value: !Ref 'AWS::StackName'
  InternetGateway:
    Type: 'AWS::EC2::InternetGateway'
    Properties:
      Tags:
        - Key: Stack Name
          Value: !Ref 'AWS::StackName'
  VPCGatewayAttachment:
    Type: 'AWS::EC2::VPCGatewayAttachment'
    Properties:
      VpcId: !Ref VPC
      InternetGatewayId: !Ref InternetGateway
  SubnetA:
    Type: 'AWS::EC2::Subnet'
    Properties:
      Tags:
        - Key: Stack Name
          Value: !Ref 'AWS::StackName'
      VpcId: !Ref VPC
      CidrBlock: 10.0.1.0/24
      AvailabilityZone: !Select 
        - 0
        - Fn::GetAZs: !Ref 'AWS::Region'
  SubnetB:
    Type: 'AWS::EC2::Subnet'
    Properties:
      Tags:
        - Key: Stack Name
          Value: !Ref 'AWS::StackName'
      VpcId: !Ref VPC
      CidrBlock: 10.0.2.0/24
      AvailabilityZone: !Select 
        - 1
        - Fn::GetAZs: !Ref 'AWS::Region'
  SecurityGroup:
    Type: 'AWS::EC2::SecurityGroup'
    Properties:
      Tags:
        - Key: Stack Name
          Value: !Ref 'AWS::StackName'
      GroupDescription: Allow SSH and custom port 4001 TCP access
      VpcId: !Ref VPC
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: 22
          ToPort: 22
          CidrIp: 0.0.0.0/0
        - IpProtocol: tcp
          FromPort: 4001
          ToPort: 4001
          CidrIp: 0.0.0.0/0
  RouteTable:
    Type: AWS::EC2::RouteTable
    Properties:
      Tags:
        - Key: Stack Name
          Value: !Ref 'AWS::StackName'
      VpcId: !Ref VPC
  Route:
    Type: AWS::EC2::Route
    DependsOn:
      - InternetGateway
      - RouteTable
      - VPCGatewayAttachment
    Properties:
      RouteTableId: !Ref RouteTable
      DestinationCidrBlock: 0.0.0.0/0
      GatewayId: !Ref InternetGateway
  RouteSubnetA:
    Type: "AWS::EC2::SubnetRouteTableAssociation"
    DependsOn:
      - RouteTable
      - SubnetA
      - Route
    Properties:
      RouteTableId: !Ref RouteTable
      SubnetId: !Ref SubnetA
  RouteSubnetB:
    Type: "AWS::EC2::SubnetRouteTableAssociation"
    DependsOn:
      - RouteTable
      - SubnetB
      - Route
    Properties:
      RouteTableId: !Ref RouteTable
      SubnetId: !Ref SubnetB
  NodeLaunchTemplate:
    Type: 'AWS::EC2::LaunchTemplate'
    Properties:
      LaunchTemplateName: NodeLaunchTemplate
      LaunchTemplateData:
        ImageId: !Sub "${LatestAmazonLinuxAMIId}"
        InstanceType: t3.medium
        BlockDeviceMappings:
          - DeviceName: /dev/xvda
            Ebs:
              VolumeSize: 60
              DeleteOnTermination: true
        KeyName: NodeKey
        NetworkInterfaces:
          - AssociatePublicIpAddress: true
            DeviceIndex: 0
            Groups: 
             - !Ref SecurityGroup
        UserData:
          Fn::Base64: !Sub |
            #cloud-config
            output: {all: '| tee -a /var/log/cloud-init-output.log'}
            runcmd:
              - yum update -y
              - yum install docker -y
              - systemctl enable --now docker
              - wget --trust-server-names -O ~/Node.tar.gz https://links.gala.com/DownloadLinuxNode
              - tar xzvf ~/Node.tar.gz -C ~/
              - sed -i 's/\/usr\/local\/bin\/kubectl/\/usr\/bin\/kubectl/g; s/\/usr\/local\/bin\/gala-node/\/usr\/bin\/gala-node/g' ~/gala-node/install.sh
              - ~/gala-node/install.sh -y
              - export HOME=/root
              - gala-node config api-key ${APIKey}
              - gala-node config workloads ${Workloads}
              - gala-node start
              - bash -c 'printf "#!/bin/bash\necho \"Startup update at \$(date)\"\nyum update -y\ngala-node update -y\necho \"Finished update at \$(date)\"" > /var/lib/cloud/scripts/per-boot/startup.sh && chmod 744 /var/lib/cloud/scripts/per-boot/startup.sh'
        InstanceMarketOptions:
          MarketType: spot
          SpotOptions:
            SpotInstanceType: one-time
  NodeKey:
    Type: 'AWS::EC2::KeyPair'
    Properties:
      KeyName: NodeKey
      Tags:
        - Key: Stack Name
          Value: !Ref 'AWS::StackName'
  NodeScalingGroup: 
      Type: 'AWS::AutoScaling::AutoScalingGroup'
      DependsOn: NodeLaunchTemplate
      Properties:
        LaunchTemplate:
          LaunchTemplateId: !Ref NodeLaunchTemplate
          Version: !GetAtt NodeLaunchTemplate.DefaultVersionNumber
        VPCZoneIdentifier:
          - !Ref SubnetA
          - !Ref SubnetB
        DesiredCapacity: '2'
        MinSize: '2'
        MaxSize: '2'
        Tags:
          - Key: Stack Name
            Value: !Ref 'AWS::StackName'
            PropagateAtLaunch: true
          - Key: 'Name'
            PropagateAtLaunch: true
            Value: 'Node Instance'
        LifecycleHookSpecificationList:
        - LifecycleTransition: autoscaling:EC2_INSTANCE_LAUNCHING
          LifecycleHookName: LogAutoScalingEvent-hook
          DefaultResult: ABANDON
          HeartbeatTimeout: 300
  StartInstances: 
    Type: AWS::AutoScaling::ScheduledAction
    Properties:
      AutoScalingGroupName: !Ref NodeScalingGroup
      DesiredCapacity: 2
      Recurrence: "0 7 * * *"
  StopInstances: 
    Type: AWS::AutoScaling::ScheduledAction
    Properties:
      AutoScalingGroupName: !Ref NodeScalingGroup
      DesiredCapacity: 0
      Recurrence: "0 19 * * *"
  NodeSpotInstanceSnapshotBackupExecutionRole:
    Type: "AWS::IAM::Role"
    Properties:
      Tags:
        - Key: Stack Name
          Value: !Ref 'AWS::StackName'
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: "Allow"
            Principal:
              Service: "lambda.amazonaws.com"
            Action: "sts:AssumeRole"
      Path: "/"
      Policies:
        - PolicyName: "NodeSpotInstanceSnapshotBackupPolicy"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: "Allow"
                Action:
                  - "ec2:DescribeInstances"
                  - "ec2:DeleteSnapshot"
                  - "ec2:CreateTags"
                  - "ec2:CreateSnapshot"
                  - "ec2:DescribeSnapshots"
                  - "ec2:DescribeVolumes"
                  - "ec2:CreateVolume"
                  - "ec2:GetWaiter"
                  - "ec2:DeleteVolume"
                  - "ec2:AttachVolume"
                  - "ec2:DetachVolume"
                  - "ec2:StopInstances"
                  - "ec2:StartInstances"
                  - "autoscaling:CompleteLifecycleAction"
                Resource: "*"
              - Effect: "Allow"
                Action:
                  - "logs:CreateLogGroup"
                  - "logs:CreateLogStream"
                  - "logs:PutLogEvents"
                Resource: !Sub "arn:aws:logs:${AWS::Region}:${AWS::AccountId}:*"
  NodeSpotInstanceSnapshotBackup:
    Type: AWS::Lambda::Function
    Properties:
      Code:
        ZipFile: |
          import boto3
          import os
          import json
          import logging

          logger = logging.getLogger()
          logger.setLevel(logging.INFO)

          ec2 = boto3.client('ec2')

          def lambda_handler(event, context):
            logger.info('Received event: %s', json.dumps(event))

            # Extract instance ID from the event
            instance_id = event['instance-id']

            logger.info('Instance ID: %s', instance_id)

            # Retrieve information about the instance
            instance_data = ec2.describe_instances(InstanceIds=[instance_id])
            az = instance_data['Reservations'][0]['Instances'][0]['Placement']['AvailabilityZone']
            volume_id = instance_data['Reservations'][0]['Instances'][0]['BlockDeviceMappings'][0]['Ebs']['VolumeId']
            logger.info('Availability Zone: %s, Volume ID: %s', az, volume_id)

            stack_name = os.environ['StackName']
            logger.info('Stack Name: %s', stack_name)

            # Create the snapshot and tag it with stack name, availability zone, and a name tag
            snapshot_name = f'{stack_name}-{az}'
            snapshot_description = f'Snapshot of {volume_id} for {instance_id}'
            snapshot_tags = [
                {'Key': 'Name', 'Value': snapshot_name},
                {'Key': 'StackName', 'Value': stack_name},
                {'Key': 'AvailabilityZone', 'Value': az}
            ]
            snapshot = ec2.create_snapshot(
                VolumeId=volume_id,
                Description=snapshot_description,
                TagSpecifications=[{'ResourceType': 'snapshot', 'Tags': snapshot_tags}]
            )
            logger.info('Created snapshot: %s', snapshot['SnapshotId'])

            # Find if there is already a snapshot with the same stack name and availability zone tags
            existing_snapshots = ec2.describe_snapshots(
                Filters=[
                    {'Name': 'tag:StackName', 'Values': [stack_name]},
                    {'Name': 'tag:AvailabilityZone', 'Values': [az]}
                ]
            )['Snapshots']
            if len(existing_snapshots) > 1:
                # Sort snapshots by start time (most recent first)
                sorted_snapshots = sorted(existing_snapshots, key=lambda x: x['StartTime'], reverse=True)

                # Replace the old snapshot with the newly created one by deleting all retrived snapshots except the most recent one
                for snapshot in sorted_snapshots[1:]:
                  ec2.delete_snapshot(SnapshotId=snapshot['SnapshotId'])
                  logger.info('Deleted old snapshot: %s', snapshot['SnapshotId'])

            return {
                'statusCode': 200,
                'body': json.dumps('Snapshot created successfully')
            }
      Handler: index.lambda_handler
      Role: !GetAtt NodeSpotInstanceSnapshotBackupExecutionRole.Arn
      Runtime: python3.8
      Timeout: 60
      MemorySize: 128
      Tags:
        - Key: Stack Name
          Value: !Ref 'AWS::StackName'
      Environment:
        Variables:
          StackName: !Ref 'AWS::StackName'
  NodeSpotInstanceSnapshotLoad:
    Type: AWS::Lambda::Function
    Properties:
      Code:
        ZipFile: |
          import boto3
          import os
          import json
          import logging

          logger = logging.getLogger()
          logger.setLevel(logging.INFO)

          def lambda_handler(event, context):
              logger.info('Received event: %s', json.dumps(event))
              autoscaling = boto3.client('autoscaling', region_name=event['region'])
              ec2 = boto3.client('ec2', region_name=event['region'])
              eventDetail = event['detail']
              response = {}
              params = {
                  'AutoScalingGroupName': eventDetail['AutoScalingGroupName'],
                  'LifecycleActionResult': 'CONTINUE',
                  'LifecycleHookName': eventDetail['LifecycleHookName'],
                  'InstanceId': eventDetail['EC2InstanceId'],
                  'LifecycleActionToken': eventDetail['LifecycleActionToken']
              }
              ## retrive the instance id from the event
              instance_id = eventDetail['EC2InstanceId']
              logger.info('Instance ID: %s', instance_id)

              ## retrive the stack name from the OS environment variable
              stack_name = os.environ['StackName']
              logger.info('Stack Name: %s', stack_name)

              ## Retrieve information about the instance
              instance_data = ec2.describe_instances(InstanceIds=[instance_id])
              az = instance_data['Reservations'][0]['Instances'][0]['Placement']['AvailabilityZone']
              volume_id = instance_data['Reservations'][0]['Instances'][0]['BlockDeviceMappings'][0]['Ebs']['VolumeId']

              ## Retrive original volume data
              original_volume_data = ec2.describe_volumes(VolumeIds=[volume_id])
              logger.info('Original Volume Data: %s', original_volume_data['Volumes'][0])

              ## Retrive original volume id
              original_volume_id = original_volume_data['Volumes'][0]['VolumeId']
              logger.info('Original Volume ID: %s', original_volume_id)
              
              ## Retrive the original volume attachment device name
              device_name = original_volume_data['Volumes'][0]['Attachments'][0]['Device']
              logger.info('Device Name: %s', device_name)

              ## Snapshot name
              snapshot_name = f'{stack_name}-{az}'
              logger.info('Snapshot Name: %s', snapshot_name)

              ## Find the snapshot by name
              snapshot_data = ec2.describe_snapshots(Filters=[{'Name': 'tag:Name', 'Values': [snapshot_name]}])
              logger.info('Snapshot Data: %s', snapshot_data)

              ## If no snapshot is found, continue the lifecycle action
              if len(snapshot_data['Snapshots']) > 0:
                ## Sort the snapshots by date and get the latest one
                snapshot_data['Snapshots'].sort(key=lambda x: x['StartTime'], reverse=True)
                snapshot_id = snapshot_data['Snapshots'][0]['SnapshotId']
                try:
                  #create a new volume from the snapshot using the same data as the original volume
                  new_volume_data = ec2.create_volume(
                      AvailabilityZone=az,
                      SnapshotId=snapshot_id,
                      VolumeType=original_volume_data['Volumes'][0]['VolumeType'],
                      Encrypted=original_volume_data['Volumes'][0]['Encrypted'],
                      Size=original_volume_data['Volumes'][0]['Size'],
                      TagSpecifications=[
                          {
                              'ResourceType': 'volume',
                              'Tags': [
                                  {
                                      'Key': 'Name',
                                      'Value': f'{stack_name}-{az}'
                                  },
                              ]
                          },
                      ]
                  )
                  logger.info('New Volume Data: %s', new_volume_data)
                  new_volume_id = new_volume_data['VolumeId']
                  logger.info('New Volume ID: %s', new_volume_id)
                  # Stop the instance
                  ec2.stop_instances(InstanceIds=[instance_id])
                  waiter = ec2.get_waiter('instance_stopped')
                  waiter.wait(InstanceIds=[instance_id])
                  #detach the old volume
                  ec2.detach_volume(
                      Device=device_name,
                      InstanceId=instance_id,
                      VolumeId=original_volume_id
                  )
                  #wait for the volume to be detached
                  waiter = ec2.get_waiter('volume_available')
                  waiter.wait(VolumeIds=[original_volume_id])
                  logger.info('Volume detached from instance: %s', original_volume_id)
                  #delete the old volume
                  ec2.delete_volume(
                      VolumeId=original_volume_id
                  )
                  logger.info('Volume deleted: %s', original_volume_id)
                  ## Wait for the volume to be available
                  waiter = ec2.get_waiter('volume_available')
                  waiter.wait(VolumeIds=[new_volume_id])
                  logger.info('Volume created from snapshot: %s', new_volume_id)
                  #attach the new volume to the instance using the same device name as the original volume
                  ec2.attach_volume(
                      Device=device_name,
                      InstanceId=instance_id,
                      VolumeId=new_volume_id
                  )
                  #wait for the volume to be attached
                  waiter = ec2.get_waiter('volume_in_use')
                  waiter.wait(VolumeIds=[new_volume_id])
                  logger.info('Volume attached to instance: %s', new_volume_id)
                  ec2.start_instances(InstanceIds=[instance_id])
                except Exception as e:
                  logger.error('Error completing lifecycle action: %s', e)
                  response = {
                      'statusCode': 500,
                      'body': 'ERROR'
                  }
              if response:
                return response
              try:
                data = autoscaling.complete_lifecycle_action(**params)
                logger.info('Lifecycle action completed: %s', data)
                response = {
                  'statusCode': 200,
                  'body': 'SUCCESS'
                }
              except Exception as e:
                logger.error('Error completing lifecycle action: %s', e)
                response = {
                  'statusCode': 500,
                  'body': 'ERROR'
                }
              return response
      Handler: index.lambda_handler
      Role: !GetAtt NodeSpotInstanceSnapshotBackupExecutionRole.Arn
      Runtime: python3.8
      Timeout: 300
      MemorySize: 128
      Tags:
        - Key: Stack Name
          Value: !Ref 'AWS::StackName'
      Environment:
        Variables:
          StackName: !Ref 'AWS::StackName'
  NodeSpotInstanceTerminationRule:
    Type: AWS::Events::Rule
    Properties:
      Name: NodeSpotInstanceTerminationRule
      Description: Trigger NodeSpotInstanceSnapshotBackup when a spot instance is terminated
      EventPattern:
        source:
          - aws.ec2
        detail-type:
          - EC2 Spot Instance Interruption Warning
        detail:
          instance-action: 
            - terminate
      State: ENABLED
      Targets:
        - Arn: !GetAtt NodeSpotInstanceSnapshotBackup.Arn
          Id: NodeSpotInstanceSnapshotBackup
          InputTransformer:
            InputPathsMap:
              instance_id: "$.detail.instance-id"
            InputTemplate: '{"instance-id": <instance_id>}'
  LogAutoScalingEventRule:
    Type: AWS::Events::Rule
    Properties:
      Name: LogAutoScalingEvent-rule
      Description: Catch the AutoScaling scale out to trigger a Lambda function
      EventPattern:
        source:
          - aws.autoscaling
        detail-type:
          - EC2 Instance-launch Lifecycle Action
      State: ENABLED
      Targets:
        - Arn: !GetAtt NodeSpotInstanceSnapshotLoad.Arn
          Id: NodeSpotInstanceSnapshotLoad
  NodeSpotInstanceTerminationPolicy:
    Type: AWS::Lambda::Permission
    Properties:
      Action: lambda:InvokeFunction
      FunctionName: !GetAtt NodeSpotInstanceSnapshotBackup.Arn
      Principal: events.amazonaws.com
      SourceArn: !GetAtt NodeSpotInstanceTerminationRule.Arn
  LogAutoScalingEventRulePolicy:
    Type: AWS::Lambda::Permission
    Properties:
      Action: lambda:InvokeFunction
      FunctionName: !GetAtt NodeSpotInstanceSnapshotLoad.Arn
      Principal: events.amazonaws.com
      SourceArn: !GetAtt LogAutoScalingEventRule.Arn  
Outputs:
  VPCID:
    Description: VPC ID
    Value: !Ref VPC
  SubnetAID:
    Description: Public Subnet A ID
    Value: !Ref SubnetA
  SubnetBID:
    Description: Public Subnet B ID
    Value: !Ref SubnetB
  NodeLaunchTemplateID:
    Description: Node Launch Template
    Value: !Ref NodeLaunchTemplate
  NodeScalingGroupID:
    Description: Node Scaling Group
    Value: !Ref NodeScalingGroup
  NodeKeyID:
    Description: Node Key Name
    Value: !Ref NodeKey
  SecurityGroupID:
    Description: Security group created
    Value: !Ref SecurityGroup
